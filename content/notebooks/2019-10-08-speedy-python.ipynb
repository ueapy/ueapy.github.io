{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"2019-10-08-speedy-python\"\n",
    "title = \"Speeding up python using tools from the standard library\"\n",
    "tags = \"basics, optimisation, numpy, multiprocessing\"\n",
    "author = \"Callum Rollo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb_tools import connect_notebook_to_post\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "html = connect_notebook_to_post(name, title, tags, author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate Python's performance, we'll use a short function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart2pol(x, y):\n",
    "    r = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "    return(r, phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the name suggest **cart2pol** converts a pair of cartesian coordinates [x, y] to polar coordinates [r, phi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/78/Polar_to_cartesian.svg/1024px-Polar_to_cartesian.svg.png\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import Image \n",
    "Image(url='https://upload.wikimedia.org/wikipedia/commons/thumb/7/78/Polar_to_cartesian.svg/1024px-Polar_to_cartesian.svg.png',width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0 0.9272952180016122\n"
     ]
    }
   ],
   "source": [
    "x = 3\n",
    "y = 4\n",
    "r, phi = cart2pol(x,y)\n",
    "print(r,phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All well and good. However, what if we want to convert a list of cartesian coordinates to polar coordinates?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could **loop** through both lists and perform the conversion for each x-y pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart2pol_list(list_x, list_y):\n",
    "    # Prepare empty lists for r and phi values\n",
    "    r = np.empty(len(list_x))\n",
    "    phi = np.empty(len(list_x))\n",
    "    \n",
    "    # Loop through the lists of x and y, calculating the r and phi values\n",
    "    for i in range(len(list_x)):\n",
    "        r[i] = np.sqrt(list_x[i]**2 + list_y[i]**2)\n",
    "        phi[i] = np.arctan2(list_y[i], list_x[i])\n",
    "    \n",
    "    return(r, phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = np.sin(np.arange(0,2*np.pi,0.1))\n",
    "y_list = np.cos(np.arange(0,2*np.pi,0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These coordinates make a circle centered at [0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fedf547b8d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,6))\n",
    "ax.scatter(x_list,y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[ 1.57079633  1.47079633  1.37079633  1.27079633  1.17079633  1.07079633\n",
      "  0.97079633  0.87079633  0.77079633  0.67079633  0.57079633  0.47079633\n",
      "  0.37079633  0.27079633  0.17079633  0.07079633 -0.02920367 -0.12920367\n",
      " -0.22920367 -0.32920367 -0.42920367 -0.52920367 -0.62920367 -0.72920367\n",
      " -0.82920367 -0.92920367 -1.02920367 -1.12920367 -1.22920367 -1.32920367\n",
      " -1.42920367 -1.52920367 -1.62920367 -1.72920367 -1.82920367 -1.92920367\n",
      " -2.02920367 -2.12920367 -2.22920367 -2.32920367 -2.42920367 -2.52920367\n",
      " -2.62920367 -2.72920367 -2.82920367 -2.92920367 -3.02920367 -3.12920367\n",
      "  3.05398163  2.95398163  2.85398163  2.75398163  2.65398163  2.55398163\n",
      "  2.45398163  2.35398163  2.25398163  2.15398163  2.05398163  1.95398163\n",
      "  1.85398163  1.75398163  1.65398163]\n"
     ]
    }
   ],
   "source": [
    "r_list, phi_list = cart2pol_list(x_list,y_list)\n",
    "print(r_list)\n",
    "print(phi_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit time consuming to type out though, surely there is a better way to make our functions work for lists of inputs?\n",
    "\n",
    "Step forward **vectorise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart2pol_vec = np.vectorize(cart2pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_list_vec, phi_list_vec = cart2pol_vec(x_list, y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like magic! We can assure ourselves that these two methods produce the same answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "print(r_list == r_list_vec)\n",
    "print(phi_list == phi_list_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how do they perform?\n",
    "\n",
    "We can use Python's magic **%timeit** function to test this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272 µs ± 24.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit cart2pol_list(x_list, y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161 µs ± 9.19 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit cart2pol_vec(x_list, y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is significantly faster, both for code writing and at runtime, to use **vectorsie** rather than manually looping through lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing\n",
    "Another important consideration when code becomes computationally intensive is **multiprocessing**. Python normally runs on one core, so you won't feel the full benefit of your quad-core or greater machine. You can see this when you run a section of code. To demonstrate the effect of multiprocessing we'll need some heftier maths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_maths(start=0, num=10):\n",
    "    pos = start\n",
    "    big = 1000 * 1000\n",
    "    ave = 0\n",
    "    while pos < num:\n",
    "        pos += 1\n",
    "        val = math.sqrt((pos - big) * (pos - big))\n",
    "        ave += val / num\n",
    "\n",
    "    return int(ave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 8.93 sec.\n"
     ]
    }
   ],
   "source": [
    "t0 = datetime.now()\n",
    "\n",
    "do_maths(num=30000000)\n",
    "\n",
    "dt = datetime.now() - t0\n",
    "print(\"Done in {:,.2f} sec.\".format(dt.total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing with 4 processor(s)\n",
      "Done in 4.05 sec.\n"
     ]
    }
   ],
   "source": [
    "t0 = datetime.now()\n",
    "\n",
    "pool = multiprocessing.Pool()\n",
    "processor_count = multiprocessing.cpu_count()\n",
    "# processor_count = 2 # we can Python to use a specific number of cores if desired\n",
    "\n",
    "print(f\"Computing with {processor_count} processor(s)\")\n",
    "tasks = []\n",
    "for n in range(1, processor_count + 1):\n",
    "    task = pool.apply_async(do_maths, (30000000 * (n - 1) / processor_count,\n",
    "                                      30000000 * n / processor_count))\n",
    "    \n",
    "    tasks.append(task)\n",
    "\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "dt = datetime.now() - t0\n",
    "print(\"Done in {:,.2f} sec.\".format(dt.total_seconds()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can recover results stored in the task list with get(). This list will be in the same order as that which you used to spawn the processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2883333\n",
      "5125000\n",
      "5916666\n",
      "6312500\n"
     ]
    }
   ],
   "source": [
    "for t in tasks:\n",
    "    print(t.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of a multiproccess call is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npool = multiprocessing.Pool() # Make a pool ready to recieve taks\\nresults = [] # empty list for results\\nfor n in range(1, processor_count + 1): # Loop for assigning a number of tasks\\n    result = pool.appy_async(function, (arguments)) # make a task by passing it a function and arguments\\n    results.append(result) # append the result(s) of this task to the list\\n\\npool.close() # tell async there are no more tasks coming\\npool.join() # start running the tasks concurrently\\n\\nfor t in results:\\n    t.get() # ret`rieve your results, You could print or assign each result to a variable\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = multiprocessing.Pool() # Make a pool ready to recieve taks\n",
    "results = [] # empty list for results\n",
    "for n in range(1, processor_count + 1): # Loop for assigning a number of tasks\n",
    "    result = pool.appy_async(function, (arguments)) # make a task by passing it a function and arguments\n",
    "    results.append(result) # append the result(s) of this task to the list\n",
    "\n",
    "pool.close() # tell async there are no more tasks coming\n",
    "pool.join() # start running the tasks concurrently\n",
    "\n",
    "for t in results:\n",
    "    t.get() # ret`rieve your results, You could print or assign each result to a variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why can't we multithread in Python?\n",
    "\n",
    "If you have experience of other programming languages, you may wonder why we can't assign tasks to multiple threads to speed up execution. We are prevented from doing this by the Global Interpreter Lock (GIL). This is a lock on the interpreter which ensures that only one thread can be in a state of execution at any one time. This is essential to protect Python's reference system that keeps track of all of the objects in memory. \n",
    "\n",
    "To get around this lock we spawn several processes which each have their own instance of the interpreter and allocated memory so cannot block one another or cause mischief with references. There's a great summary of the GIL on the real Python website [here](https://realpython.com/python-gil/)\n",
    "\n",
    "**tl;dr** multithreading won't speed up your compute heavy calcualtions as only one thread can execute at any. time. Use multiprocessing instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiprocessing example adapted from [Talk Python To Me Training: async techniques](https://training.talkpython.fm/courses/details/async-in-python-with-threading-and-multiprocessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <small>\n",
       "    <p> This post was written as an IPython (Jupyter) notebook. You can view or download it using\n",
       "    <a href=\"http://nbviewer.ipython.org/github/ueapy/ueapy.github.io/blob/src/content/notebooks/2019-10-08-speedy-python.ipynb\">nbviewer</a>.</p>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
